{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef4490e2",
   "metadata": {},
   "source": [
    "# 가위바위보 분류기를 만들자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec045d5",
   "metadata": {},
   "source": [
    "### 라이브러리 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "738ddb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.21.4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b69504",
   "metadata": {},
   "source": [
    "### 데이터 불러오기 + Resize 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b44d2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8d87c8",
   "metadata": {},
   "source": [
    "### 이미지의 크기를 28 x 28로 만든다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8bec78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500  images to be resized.\n",
      "500  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "500  images to be resized.\n",
      "500  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "500  images to be resized.\n",
      "500  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca71c814",
   "metadata": {},
   "source": [
    "### load_data() 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "913cd2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 1500 입니다.\n",
      "x_train shape: (1503, 28, 28, 3)\n",
      "y_train shape: (1503,)\n"
     ]
    }
   ],
   "source": [
    "# 가위바위보 데이터를 읽을 수 있는 load_data() 함수 만들기\n",
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=1503):  # 가위바위보 이미지 개수 총합: 1503\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44466dc6",
   "metadata": {},
   "source": [
    "### 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7832a93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 38)                30438     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 117       \n",
      "=================================================================\n",
      "Total params: 35,643\n",
      "Trainable params: 35,643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# 모델 만들기\n",
    "# 텐서플로우(TensorFlow)의 표준 API인 tf.keras의 Sequential API를 이용\n",
    "n_channel_1=16  # 얼마나 다양한 이미지의 특징을 살펴볼 것인가?\n",
    "n_channel_2=32\n",
    "n_dense=38    # 분류기 알고리즘을 얼마나 복잡하게 할 것인가? (복잡한 문제일수록 늘릴 것)\n",
    "n_train_epoch=3    # 가위바위보의 분류기 값이므로 3으로 맞춰준다(가위, 바위, 보)\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))    # RGB 색상이므로 28,28,'3'\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(n_train_epoch, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers)) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a012e1",
   "metadata": {},
   "source": [
    "### 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c181e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47/47 [==============================] - 3s 5ms/step - loss: 5.2273 - accuracy: 0.3187\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 1.0758 - accuracy: 0.4943\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9641 - accuracy: 0.5436\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.8672 - accuracy: 0.5848\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.7548 - accuracy: 0.6580\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6864 - accuracy: 0.6966\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.7445\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7858\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7924\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.8057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa6e5a17bb0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1380e743",
   "metadata": {},
   "source": [
    "### 얼마나 잘 만들었는지 확인하기(테스트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a54b9785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201  images to be resized.\n",
      "201  images resized.\n",
      "199  images to be resized.\n",
      "199  images resized.\n",
      "200  images to be resized.\n",
      "200  images resized.\n",
      "학습데이터(x_train)의 이미지 개수는 600 입니다.\n",
      "x_test shape: (1503, 28, 28, 3)\n",
      "y_test shape: (1503,)\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "# 테스트 가위 이미지 resize 완료\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "# 테스트 바위 이미지 resize 완료\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "# 테스트 보 이미지 resize 완료\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdc06dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 - 0s - loss: 0.4854 - accuracy: 0.8144\n",
      "test_loss: 0.4853745400905609\n",
      "test_accuracy: 0.8143712282180786\n"
     ]
    }
   ],
   "source": [
    "# loss, accuracy 체크\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test,y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss}\")\n",
    "print(f\"test_accuracy: {test_accuracy}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5bf892",
   "metadata": {},
   "source": [
    "<회고> <br>\n",
    "가위바위보 분류기를 만드는 실습을 해보았는데,<br> \n",
    "텐서플로우를 활용해서 모델 학습을 할 수 있다는 게 참 편리하다는 생각이 들었다.<br>\n",
    "\n",
    "- 데이터 불러와서 resize 하기\n",
    "- load_data() 함수 만들기\n",
    "- 딥러닝 네트워크 설계: (tensowflow의 표준 API인 tf.keras의 Sequential API를 이용)\n",
    "- 딥러닝 네트워크 학습시키기: model.compile, model.fit\n",
    "- 테스트하기: 테스트 데이터 불러와서 resize, 정규화\n",
    "- loss, accuracy 확인\n",
    "<br>\n",
    "<br>\n",
    "위 순서로 진행된다는 흐름을 알 수 있었다.\n",
    "\n",
    "<br>\n",
    "분류기 사용에 앞서서, 해당 노드에서 300장의 사진 데이터를 이용해보라는 권유가 있었는데<br>\n",
    "데이터량이 많을 수록 accuracy가 높아지지 않을까 싶어, <br>\n",
    "조원들과 함께 가위바위보 손 사진을 찍어 해당 사진 데이터로 분류기 작업을 진행하였다. <br>\n",
    "총 2100장의 사진을 가지고, train에는 약 1500개, test에는 약 600개의 사진을 할당하여 분류 작업을 진행하였다.<br>\n",
    "\n",
    "accuracy를 높이기 위해 dense 값을 약간 늘려주었더니,\n",
    "- 최종 test accuracy : 81.43%에 도달할 수 있었다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
