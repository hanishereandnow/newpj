{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8074022",
   "metadata": {},
   "source": [
    "# 프로젝트: 번역기를 만들어보자\n",
    "## 단어 단위 번역기 만들기: 영어-프랑스어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07a2921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "# 주요 라이브러리 버전 확인\n",
    "\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3389156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 불러오기\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f040f338",
   "metadata": {},
   "source": [
    "학습과 테스트 시의 원활한 진행을 위해서 데이터에서 상위 33,000개의 샘플만 사용하였다. <br>\n",
    "\n",
    "33000개 중 3000개는 테스트 데이터로 분리하여 모델을 학습한 후에 번역을 테스트 하는 용도로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b78f2a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 197463\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9357</th>\n",
       "      <td>Who thinks so?</td>\n",
       "      <td>Qui partage cet avis ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161315</th>\n",
       "      <td>All wished each other a Merry Christmas.</td>\n",
       "      <td>Tous se sont souhaités un joyeux Noël.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30029</th>\n",
       "      <td>I made a few calls.</td>\n",
       "      <td>J'ai passé quelques coups de fil.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138783</th>\n",
       "      <td>What are you two conspiring about?</td>\n",
       "      <td>Qu'est-ce que vous complotez tous les deux ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36877</th>\n",
       "      <td>I'm more than happy.</td>\n",
       "      <td>Je suis plus que content.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             eng  \\\n",
       "9357                              Who thinks so?   \n",
       "161315  All wished each other a Merry Christmas.   \n",
       "30029                        I made a few calls.   \n",
       "138783        What are you two conspiring about?   \n",
       "36877                       I'm more than happy.   \n",
       "\n",
       "                                                 fra  \\\n",
       "9357                          Qui partage cet avis ?   \n",
       "161315        Tous se sont souhaités un joyeux Noël.   \n",
       "30029              J'ai passé quelques coups de fil.   \n",
       "138783  Qu'est-ce que vous complotez tous les deux ?   \n",
       "36877                      Je suis plus que content.   \n",
       "\n",
       "                                                       cc  \n",
       "9357    CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "161315  CC-BY 2.0 (France) Attribution: tatoeba.org #7...  \n",
       "30029   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "138783  CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
       "36877   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5) #샘플 5개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c94be336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32461</th>\n",
       "      <td>Tom almost drowned.</td>\n",
       "      <td>Tom s'est presque noyé.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28657</th>\n",
       "      <td>Do you want to eat?</td>\n",
       "      <td>Est-ce que vous voulez manger ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>I'm ready!</td>\n",
       "      <td>Je suis prête !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10499</th>\n",
       "      <td>I have a cough.</td>\n",
       "      <td>J’ai une toux.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15314</th>\n",
       "      <td>Let's try again.</td>\n",
       "      <td>Essayons encore une fois.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       eng                              fra\n",
       "32461  Tom almost drowned.          Tom s'est presque noyé.\n",
       "28657  Do you want to eat?  Est-ce que vous voulez manger ?\n",
       "1207            I'm ready!                  Je suis prête !\n",
       "10499      I have a cough.                   J’ai une toux.\n",
       "15314     Let's try again.        Essayons encore une fois."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng', 'fra']][:33000] # 33,000개 샘플 사용\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddec1bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27443</th>\n",
       "      <td>What was your job?</td>\n",
       "      <td>\\t Quel était ton travail ? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24873</th>\n",
       "      <td>I'm really hungry.</td>\n",
       "      <td>\\t J'ai vraiment faim. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15395</th>\n",
       "      <td>My cat is black.</td>\n",
       "      <td>\\t Mon chat est noir. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20455</th>\n",
       "      <td>That isn't a cat.</td>\n",
       "      <td>\\t Ce n'est pas un chat. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32753</th>\n",
       "      <td>Tom looks relieved.</td>\n",
       "      <td>\\t Tom a l'air soulagé. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       eng                             fra\n",
       "27443   What was your job?  \\t Quel était ton travail ? \\n\n",
       "24873   I'm really hungry.       \\t J'ai vraiment faim. \\n\n",
       "15395     My cat is black.        \\t Mon chat est noir. \\n\n",
       "20455    That isn't a cat.     \\t Ce n'est pas un chat. \\n\n",
       "32753  Tom looks relieved.      \\t Tom a l'air soulagé. \\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰 추가\n",
    "sos_token = '\\t'\n",
    "eos_token = '\\n'\n",
    "lines.fra = lines.fra.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ba40c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구두점 분리\n",
    "# 소문자 바꾸기: 토크나이저에 내장되어있음\n",
    "# 띄어쓰기: 토크나이저에 내장되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b39f8246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def pad_punctuation(s): return re.sub(f\"([{string.punctuation}])\", r' \\1 ', s)\n",
    "\n",
    "# 프랑스어 구두점 분리\n",
    "def french_punctuations(s):\n",
    "    s = re.sub('[\\u202f\\u2009\\xa0]', '', s)\n",
    "    s = re.sub('’', \" ' \", s)\n",
    "    s = re.sub('[—––]', ' - ', s)\n",
    "    s = re.sub('[«»]', ' \" ', s)\n",
    "    return s\n",
    "\n",
    "# 참고: https://stackoverflow.com/questions/64125019/how-to-tokenize-punctuations-using-the-tokenizer-function-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91b5f202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50              \\t Bonjour  !  \\n\n",
       "51                \\t Salut  !  \\n\n",
       "52          \\t Je comprends .  \\n\n",
       "53                   \\t Aha .  \\n\n",
       "54            \\t J ' essaye .  \\n\n",
       "55         \\t J ' ai gagné  !  \\n\n",
       "56    \\t Je l ' ai emporté  !  \\n\n",
       "57            \\t J’ai gagné .  \\n\n",
       "58               \\t Oh non  !  \\n\n",
       "59           \\t Calme - toi .  \\n\n",
       "Name: fra, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "lines.fra = [pad_punctuation(s) for s in lines.fra]\n",
    "lines.fra[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "545a3b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50              \\t Bonjour  !  \\n\n",
       "51                \\t Salut  !  \\n\n",
       "52          \\t Je comprends .  \\n\n",
       "53                   \\t Aha .  \\n\n",
       "54            \\t J ' essaye .  \\n\n",
       "55         \\t J ' ai gagné  !  \\n\n",
       "56    \\t Je l ' ai emporté  !  \\n\n",
       "57          \\t J ' ai gagné .  \\n\n",
       "58               \\t Oh non  !  \\n\n",
       "59           \\t Calme - toi .  \\n\n",
       "Name: fra, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.fra = [french_punctuations(s) for s in lines.fra]\n",
    "lines.fra[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8e9fa4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Go . \n",
       "1    Go . \n",
       "2    Go . \n",
       "3    Go . \n",
       "4    Hi . \n",
       "Name: eng, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 구두점 분리된 영어 문장을 뽑아서 확인\n",
    "lines.eng = [pad_punctuation(s) for s in lines.eng]\n",
    "lines.eng.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b51820",
   "metadata": {},
   "source": [
    "영어와 프랑스어에 대한 토크나이저를 각각 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61f21670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[29, 1], [29, 1], [29, 1]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환하는 정수 인코딩 과정\n",
    "eng_tokenizer = Tokenizer(char_level=False, filters=\"\")   # 단어 단위로 Tokenizer를 생성합니다. \n",
    "eng_tokenizer.fit_on_texts(lines.eng)               # 33,000개의 행을 가진 eng의 각 행에 토큰화를 수행\n",
    "input_text = eng_tokenizer.texts_to_sequences(lines.eng)    # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "input_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c51df152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 74, 10, 2], [1, 339, 3, 2], [1, 27, 489, 10, 2]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_tokenizer = Tokenizer(char_level=False, filters=\"\")   # 단어 단위로 Tokenizer를 생성합니다. \n",
    "fra_tokenizer.fit_on_texts(lines.fra)                 # 33,000개의 행을 가진 fra의 각 행에 토큰화를 수행\n",
    "target_text = fra_tokenizer.texts_to_sequences(lines.fra)     # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "target_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a168e180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어장의 크기 : 4713\n",
      "프랑스어 단어장의 크기 : 8595\n"
     ]
    }
   ],
   "source": [
    "# 단어장의 크기를 변수로 저장, 0번 토큰을 고려하여 +1\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c36de60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 시퀀스의 최대 길이 10\n",
      "프랑스어 시퀀스의 최대 길이 20\n"
     ]
    }
   ],
   "source": [
    "# 패딩을 위해서 최대 길이 구하기\n",
    "max_eng_seq_len = max([len(line) for line in input_text])\n",
    "max_fra_seq_len = max([len(line) for line in target_text])\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7c061f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n",
      "영어 단어장의 크기 : 4713\n",
      "프랑스어 단어장의 크기 : 8595\n",
      "영어 시퀀스의 최대 길이 10\n",
      "프랑스어 시퀀스의 최대 길이 20\n"
     ]
    }
   ],
   "source": [
    "# 전체적인 통계 정보 출력\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "195d8fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = input_text\n",
    "\n",
    "# 종료 토큰 제거\n",
    "decoder_input = [[ char for char in line if char != fra_tokenizer.word_index[eos_token] ] for line in target_text] \n",
    "\n",
    "# 시작 토큰 제거\n",
    "decoder_target = [[ char for char in line if char != fra_tokenizer.word_index[sos_token] ] for line in target_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b158ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 74, 10], [1, 339, 3], [1, 27, 489, 10]]\n",
      "[[74, 10, 2], [339, 3, 2], [27, 489, 10, 2]]\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 입력과 출력 확인\n",
    "print(decoder_input[:3])\n",
    "print(decoder_target[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a51ea2c",
   "metadata": {},
   "source": [
    "padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "371a85ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 10)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 20)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 20)\n"
     ]
    }
   ],
   "source": [
    "# 모든 샘플들의 길이 동일하게 변환\n",
    "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc14c1d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29  1  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "# 인코더의 샘플 출력해보기\n",
    "print(encoder_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2e26a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 학습데이터의 크기(shape) : (33000, 10)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (33000, 20)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (33000, 20)\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 3000    # 검증데이터 3000개로 선택\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('영어 학습데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d736b8",
   "metadata": {},
   "source": [
    "임베딩층 사용하기\n",
    "- 입력이 되는 각 단어를 임베딩 층을 사용하여 벡터화\n",
    "- 주의할 점: 인코더와 디코더의 임베딩 층은 서로 다른 임베딩 층을 사용해야 하지만,\n",
    "- 디코더의 훈련 과정과 테스트 과정(예측 과정)에서의 임베딩 층은 동일해야"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e83087c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Masking, LSTM\n",
    "\n",
    "# 인코더에서 사용할 임베딩 층 사용\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(eng_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7886e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Masking\n",
    "\n",
    "# 디코더에서 사용할 임베딩 층 사용\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb =  Embedding(fra_vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences = True, return_state=True)\n",
    "decoder_outputs, _, _= decoder_lstm(dec_emb, initial_state = encoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b5cc54",
   "metadata": {},
   "source": [
    "글자 단위 번역기에서 구현한 모델을 참고로 단어 단위 번역기의 모델을 완성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a3305f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "print('⏳')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "355570b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c409abbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 256)    1206528     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 256)    2200320     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 525312      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  525312      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8595)   2208915     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 6,666,387\n",
      "Trainable params: 6,666,387\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\")    # 원핫인코딩이 아닐 때\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d398bf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "118/118 [==============================] - 10s 48ms/step - loss: 1.9352 - val_loss: 1.6235\n",
      "Epoch 2/50\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 1.2549 - val_loss: 1.4182\n",
      "Epoch 3/50\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 1.0640 - val_loss: 1.2812\n",
      "Epoch 4/50\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.9492 - val_loss: 1.1948\n",
      "Epoch 5/50\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.8650 - val_loss: 1.1161\n",
      "Epoch 6/50\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.8013 - val_loss: 1.0705\n",
      "Epoch 7/50\n",
      "118/118 [==============================] - 5s 43ms/step - loss: 0.7509 - val_loss: 1.0501\n",
      "Epoch 8/50\n",
      "118/118 [==============================] - 5s 43ms/step - loss: 0.7076 - val_loss: 1.0192\n",
      "Epoch 9/50\n",
      "118/118 [==============================] - 5s 43ms/step - loss: 0.6683 - val_loss: 0.9942\n",
      "Epoch 10/50\n",
      "118/118 [==============================] - 5s 43ms/step - loss: 0.6329 - val_loss: 0.9759\n",
      "Epoch 11/50\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.6010 - val_loss: 0.9532\n",
      "Epoch 12/50\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.5720 - val_loss: 0.9496\n",
      "Epoch 13/50\n",
      "118/118 [==============================] - 5s 43ms/step - loss: 0.5456 - val_loss: 0.9276\n",
      "Epoch 14/50\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.5210 - val_loss: 0.9210\n",
      "Epoch 15/50\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.4977 - val_loss: 0.9058\n",
      "Epoch 16/50\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.4753 - val_loss: 0.9044\n",
      "Epoch 17/50\n",
      "118/118 [==============================] - 5s 43ms/step - loss: 0.4541 - val_loss: 0.8938\n",
      "Epoch 18/50\n",
      "118/118 [==============================] - 5s 43ms/step - loss: 0.4346 - val_loss: 0.8892\n",
      "Epoch 19/50\n",
      "118/118 [==============================] - 5s 43ms/step - loss: 0.4160 - val_loss: 0.8877\n",
      "Epoch 20/50\n",
      "118/118 [==============================] - 5s 43ms/step - loss: 0.3980 - val_loss: 0.8865\n",
      "Epoch 21/50\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.3809 - val_loss: 0.8780\n",
      "Epoch 22/50\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.3647 - val_loss: 0.8791\n",
      "Epoch 23/50\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.3487 - val_loss: 0.8757\n",
      "Epoch 24/50\n",
      "118/118 [==============================] - 5s 43ms/step - loss: 0.3336 - val_loss: 0.8833\n",
      "Epoch 25/50\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.3192 - val_loss: 0.8862\n",
      "Epoch 26/50\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.3061 - val_loss: 0.8831\n",
      "Epoch 27/50\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.2933 - val_loss: 0.8754\n",
      "Epoch 28/50\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.2814 - val_loss: 0.8769\n",
      "Epoch 29/50\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.2702 - val_loss: 0.8867\n",
      "Epoch 30/50\n",
      "118/118 [==============================] - 5s 43ms/step - loss: 0.2593 - val_loss: 0.8883\n",
      "Epoch 31/50\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.2491 - val_loss: 0.8869\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience=4) # add early stopping\n",
    "\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size=256, epochs=50, callbacks=early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7c59c0",
   "metadata": {},
   "source": [
    "모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8d24763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot loss\n",
    "history_dict = history.history\n",
    "print(history_dict.keys()) # keys to check parameters for plotting\n",
    "\n",
    "# acc = history_dict['accuracy']\n",
    "# val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# \"bo\" is \"dotted blue\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# \"b\" is \"blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bd8d94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 256)         1206528   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 256), (None, 256) 525312    \n",
      "=================================================================\n",
      "Total params: 1,731,840\n",
      "Trainable params: 1,731,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 인코더 정의\n",
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1439770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "\n",
    "# 이전 time step의 hidden state를 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "# 이전 time step의 cell state를 저장하는 텐서\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "# 이전 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# decoder_states_inputs를 현재 time step의 초기 상태로 사용.\n",
    "# 구체적인 동작 자체는 def decode_sequence()에 구현.\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(dec_emb, initial_state = decoder_states_inputs)\n",
    "# 현재 time step의 hidden state와 cell state를 하나의 변수에 저장.\n",
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb2415e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 256)    2200320     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  525312      embedding_1[0][0]                \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8595)   2208915     lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,934,547\n",
      "Trainable params: 4,934,547\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더 출력층 재설계\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3afc0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어에서 정수로, 정수에서 단어로 바꾸는 사전(dictionary) 준비\n",
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8121277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # 에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1,1)) \n",
    "    target_seq[0, 0] = fra2idx['\\t']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # 에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장     \n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "925b6e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: Go . \n",
      "정답 문장:  Bouge  !  \n",
      "번역기가 번역한 문장:  va ! \n",
      "-----------------------------------\n",
      "입력 문장: Hello ! \n",
      "정답 문장:  Bonjour  !  \n",
      "번역기가 번역한 문장:  bonjour ! \n",
      "-----------------------------------\n",
      "입력 문장: Got it ? \n",
      "정답 문장:  T ' as capté ?  \n",
      "번역기가 번역한 문장:  cela a - t - il l ' ai\n",
      "-----------------------------------\n",
      "입력 문장: Hang on . \n",
      "정답 문장:  Tiens bon  !  \n",
      "번역기가 번역한 문장:  attendez . \n",
      "-----------------------------------\n",
      "입력 문장: Here ' s  $ 5 . \n",
      "정답 문장:  Voilà cinq dollars .  \n",
      "번역기가 번역한 문장:  voici aux règles . \n"
     ]
    }
   ],
   "source": [
    "# 임의의 샘플 입력하여 출력 결과 테스트\n",
    "import numpy as np\n",
    "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스 (자유롭게 선택해 보세요)\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.eng[seq_index])\n",
    "    print('정답 문장:', lines.fra[seq_index][1:len(lines.fra[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68741f7",
   "metadata": {},
   "source": [
    "<회고> <br>\n",
    "영어-프랑스어 번역기를 만들어보았다\n",
    "- 관련 데이터 전처리 진행\n",
    "- seq2seq 모델 사용\n",
    "- 번역문 생성\n",
    "\n",
    "순으로 진행하였다.<br>\n",
    "\n",
    "- 아직 전반적인 과정과 코드 구현에 익숙지가 않아서 꽤나 애를 먹었다. 다른 분들의 도움을 많이 받음.\n",
    "- 개념을 어렴풋이 갖고 있는 것을 코드 쳐보는 것으로 많이 연습해봐야 할 것 같다는 생각이 든다.\n",
    "\n",
    "- 번역기는 크게 정확도가 높지는 않은 것으로 보인다. 정확도를 올리기 위해 파라미터 조정이 많이 필요할 것으로 보인다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
