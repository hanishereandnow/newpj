{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5a51ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d240b339",
   "metadata": {},
   "source": [
    "### 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e527a3ec",
   "metadata": {},
   "source": [
    "1. TensorFlow Datasets SubwordTextEncoder 를 토크나이저로 사용한다.  \n",
    "   단어보다 더 작은 단위인 Subword를 기준으로 토크나이징하고,  각 토큰을 고유한 정수로 인코딩 한다.\n",
    "2. 각 문장을 토큰화하고 각 문장의 시작과 끝을 나타내는 START_TOKEN 및 END_TOKEN을 추가한다.\n",
    "3. 최대 길이 MAX_LENGTH 인 40을 넘는 문장들은 필터링한다.\n",
    "4. MAX_LENGTH보다 길이가 짧은 문장들은 40에 맞도록 패딩 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898c4c59",
   "metadata": {},
   "source": [
    "영어 데이터와는 전혀 다른 데이터인 만큼 영어 데이터에 사용했던 전처리와 일부 동일한 전처리도 필요하겠지만 전체적으로는 다른 전처리를 수행해야 할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66588c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12시 땡!                하루가 또 가네요.      0\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
       "...                        ...                       ...    ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_data = pd.read_csv('~/aiffel/transformer_chatbot/data/ChatbotData.csv')\n",
    "chatbot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc1bcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         12시 땡!\n",
       "1                    1지망 학교 떨어졌어\n",
       "2                   3박4일 놀러가고 싶다\n",
       "3                3박4일 정도 놀러가고 싶다\n",
       "4                        PPL 심하네\n",
       "                  ...           \n",
       "11818             훔쳐보는 것도 눈치 보임.\n",
       "11819             훔쳐보는 것도 눈치 보임.\n",
       "11820                흑기사 해주는 짝남.\n",
       "11821    힘든 연애 좋은 연애라는게 무슨 차이일까?\n",
       "11822                 힘들어서 결혼할까봐\n",
       "Name: Q, Length: 11823, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_data['Q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5408a367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3박4일 놀러가고 싶다'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_data['Q'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b012be81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      하루가 또 가네요.\n",
       "1                       위로해 드립니다.\n",
       "2                     여행은 언제나 좋죠.\n",
       "3                     여행은 언제나 좋죠.\n",
       "4                      눈살이 찌푸려지죠.\n",
       "                   ...           \n",
       "11818          티가 나니까 눈치가 보이는 거죠!\n",
       "11819               훔쳐보는 거 티나나봐요.\n",
       "11820                      설렜겠어요.\n",
       "11821    잘 헤어질 수 있는 사이 여부인 거 같아요.\n",
       "11822          도피성 결혼은 하지 않길 바라요.\n",
       "Name: A, Length: 11823, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_data['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a032ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'눈살이 찌푸려지죠.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_data['A'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "903f72cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "  # 단어와 구두점 사이에 공백 추가.\n",
    "  # ex) 12시 땡! -> 12시 땡 !\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b65f587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "def load_conversations():\n",
    "    \n",
    "  questions, answers = [], []\n",
    "\n",
    "  for i in range(len(chatbot_data)):\n",
    "      # 전처리 함수를 질문과 답변에 적용.\n",
    "      questions.append(preprocess_sentence(chatbot_data['Q'][i]))\n",
    "      answers.append(preprocess_sentence(chatbot_data['A'][i]))\n",
    "\n",
    "  return questions, questions\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f413916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
    "questions, answers = load_conversations()\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4ecfb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규 표현식을 사용하여 구두점을 제거하기 전 띄어쓰기로 구두점 구분\n",
    "\n",
    "# 질문\n",
    "questions = []\n",
    "for sentence in chatbot_data['Q']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f67d7ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대답\n",
    "answers = []\n",
    "for sentence in chatbot_data['A']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baa2f376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n"
     ]
    }
   ],
   "source": [
    "# 구두점에 대해서 띄어쓰기가 잘 되었는지 확인\n",
    "print(questions[:5])\n",
    "print(answers[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b067d1",
   "metadata": {},
   "source": [
    "### 단어장 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca9ee6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문, 답변 데이터셋으로부터 단어 집합(Vocabulary) 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82ef351e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 문장 생성 과정에서 사용할 '시작 토큰'과 '종료 토큰'에 대해 임의로 단어장에 추가하여 고유한 정수 부여\n",
    "# 이미 생성된 단어장의 번호와 겹치지 않도록 각각 단어장의 크기와 그보다 1이 큰 수를 번호로 부여\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e350522d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8178]\n",
      "END_TOKEN의 번호 : [8179]\n"
     ]
    }
   ],
   "source": [
    "# 부여한 정수 출력\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])\n",
    "\n",
    "# 현재 단어장의 크기가 8178(0번부터 8717번)이라는 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c0a8651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8180\n"
     ]
    }
   ],
   "source": [
    "# 두 개의 토큰을 추가해 주었기 때문에 단어장의 크기도 +2이다\n",
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4992ce4",
   "metadata": {},
   "source": [
    "### 각 단어를 고유한 정수로 인코딩(Integer encoding) & 패딩(Padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f6779e",
   "metadata": {},
   "source": [
    "위에서 tensorflow_datasets의 SubwordTextEncoder를 사용해서 tokenizer를 정의하고 Vocabulary를 만들었다면, <br>\n",
    "tokenizer.encode()로 각 단어를 정수로 변환할 수 있고 <br> \n",
    "또는 tokenizer.decode()를 통해 정수 시퀀스를 단어 시퀀스로 변환할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "955db417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5766, 611, 2495, 4167]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2359, 7516, 7, 6279, 97, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffbccf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 문장 [2161, 782, 7612, 172, 8, 2570, 436, 48, 203]\n",
      "기존 문장: SNS 시간낭비인 거 아는데 매일 하는 중\n"
     ]
    }
   ],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()와 .decode() 테스트해보기\n",
    "# 임의의 입력 문장을 sample_string에 저장\n",
    "sample_string = questions[8]\n",
    "\n",
    "# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0847f2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2161 ----> SNS \n",
      "782 ----> 시간\n",
      "7612 ----> 낭비\n",
      "172 ----> 인 \n",
      "8 ----> 거 \n",
      "2570 ----> 아는데 \n",
      "436 ----> 매일 \n",
      "48 ----> 하는 \n",
      "203 ----> 중\n"
     ]
    }
   ],
   "source": [
    "# 각 정수는 각 단어와 어떻게 mapping되는지 병렬로 출력\n",
    "# 서브워드텍스트인코더는 의미있는 단위의 서브워드로 토크나이징한다. 띄어쓰기 단위 X 형태소 분석 단위 X\n",
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3bcf953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 패딩하기: 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이: 40으로 정의\n",
    "# MAX_LENGTH = 40\n",
    "\n",
    "# # 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
    "# def tokenize_and_filter(inputs, outputs):\n",
    "#   tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "#   for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "#     # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
    "#     sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "#     sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "#     tokenized_inputs.append(sentence1)\n",
    "#     tokenized_outputs.append(sentence2)\n",
    "\n",
    "#   # 패딩\n",
    "#   tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "#       tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "#   tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "#       tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "#   return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05493e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 패딩하기: 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이: 40으로 정의\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e72f42cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8180\n",
      "필터링 후의 질문 샘플 개수: 11823\n",
      "필터링 후의 답변 샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ba821",
   "metadata": {},
   "source": [
    "### 교사 강요(Teacher Forcing) 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "805166fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]    # 디코더의 입력값으로 answers[:, :-1] 사용: END TOKEN 제외하고 넣기\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]   # 디코더의 레이블로 answers[:, 1:] 사용: START TOKEN 제외하고 넣기\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c29ecf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "[[3844   74 7894    1 8179    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
    "print(answers[0]) # 기존 샘플\n",
    "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
    "print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0432caf",
   "metadata": {},
   "source": [
    "### 마스킹(Masking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b15fb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 패딩 마스킹\n",
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "910db9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 1. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 테스트\n",
    "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))\n",
    "\n",
    "# 오직 숫자가 0인 위치에서만 숫자 1이 나오고 숫자 0이 아닌 위치에서는 숫자 0인 벡터를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7545ad9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 룩 어헤드 마스킹: 다음 단어 가리기\n",
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b23b9f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 테스트\n",
    "print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))\n",
    "    \n",
    "# 이 마스킹과 패딩 마스킹은 별개이므로, 이 마스킹을 수행할 때 만약에 숫자 0인 단어가 있다면 이 또한 패딩 해야 합니다. \n",
    "# 그래서 create_look_ahead_mask() 함수는 내부적으로 앞서 구현한 패딩 마스크 함수도 호출하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0316a499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[1. 1. 1. 1. 1.]\n",
      "   [1. 0. 1. 1. 1.]\n",
      "   [1. 0. 0. 1. 1.]\n",
      "   [1. 0. 0. 0. 1.]\n",
      "   [1. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 숫자 0이 포함되었을 때 테스트\n",
    "print(create_look_ahead_mask(tf.constant([[0, 5, 1, 5, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79820e4c",
   "metadata": {},
   "source": [
    "### 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40bcdff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa930db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 인코더 층을 쌓아 인코더 만들기\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b2fdf3",
   "metadata": {},
   "source": [
    "### 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca073d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0581f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 디코더 층을 쌓아 디코더 만들기\n",
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786eb50c",
   "metadata": {},
   "source": [
    "### 트랜스포머 함수 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ebfd97f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713416e6",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd99b726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d65c7d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 행의 크기가 50, 열의 크기가 512인 행렬을 그려보기\n",
    "sample_pos_encoding = PositionalEncoding(50, 512)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba49c6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c18f1414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b617d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3148288     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3675648     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8180)   2102260     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,926,196\n",
      "Trainable params: 8,926,196\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031240f6",
   "metadata": {},
   "source": [
    "### 손실함수(Loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5001f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc210cc2",
   "metadata": {},
   "source": [
    "### 커스텀 된 학습률(Learning rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df37309d",
   "metadata": {},
   "source": [
    "-  커스텀 학습률 스케줄링(Custom Learning rate Scheduling)\n",
    "<br> : 모델학습 초기에 learning rate를 급격히 높였다가, \n",
    "<br> 이후 train step이 진행됨에 따라 서서히 낮추어 가면서 안정적으로 수렴하게 하는 고급 기법을 널리 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa8348f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "526c5bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=256)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2c111d",
   "metadata": {},
   "source": [
    "### 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9293c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25866603",
   "metadata": {},
   "source": [
    "### 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ba8bef41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0077 - accuracy: 0.1733\n",
      "Epoch 2/100\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0079 - accuracy: 0.1732\n",
      "Epoch 3/100\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0074 - accuracy: 0.1733\n",
      "Epoch 4/100\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0073 - accuracy: 0.1734\n",
      "Epoch 5/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0069 - accuracy: 0.1734\n",
      "Epoch 6/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0069 - accuracy: 0.1734\n",
      "Epoch 7/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0061 - accuracy: 0.1736\n",
      "Epoch 8/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0060 - accuracy: 0.1736\n",
      "Epoch 9/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0058 - accuracy: 0.1737\n",
      "Epoch 10/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0056 - accuracy: 0.1737\n",
      "Epoch 11/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0053 - accuracy: 0.1738\n",
      "Epoch 12/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0051 - accuracy: 0.1738\n",
      "Epoch 13/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0052 - accuracy: 0.1738\n",
      "Epoch 14/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0050 - accuracy: 0.1739\n",
      "Epoch 15/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0049 - accuracy: 0.1739\n",
      "Epoch 16/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0047 - accuracy: 0.1740\n",
      "Epoch 17/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0044 - accuracy: 0.1740\n",
      "Epoch 18/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0045 - accuracy: 0.1740\n",
      "Epoch 19/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0045 - accuracy: 0.1740\n",
      "Epoch 20/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0041 - accuracy: 0.1740\n",
      "Epoch 21/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0040 - accuracy: 0.1741\n",
      "Epoch 22/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0039 - accuracy: 0.1741\n",
      "Epoch 23/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0037 - accuracy: 0.1741\n",
      "Epoch 24/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0038 - accuracy: 0.1741\n",
      "Epoch 25/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0037 - accuracy: 0.1741\n",
      "Epoch 26/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0037 - accuracy: 0.1741\n",
      "Epoch 27/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0037 - accuracy: 0.1741\n",
      "Epoch 28/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0034 - accuracy: 0.1742\n",
      "Epoch 29/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0033 - accuracy: 0.1742\n",
      "Epoch 30/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0033 - accuracy: 0.1742\n",
      "Epoch 31/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0032 - accuracy: 0.1742\n",
      "Epoch 32/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0032 - accuracy: 0.1742\n",
      "Epoch 33/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0030 - accuracy: 0.1743\n",
      "Epoch 34/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0029 - accuracy: 0.1743\n",
      "Epoch 35/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0031 - accuracy: 0.1743\n",
      "Epoch 36/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0029 - accuracy: 0.1743\n",
      "Epoch 37/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0030 - accuracy: 0.1743\n",
      "Epoch 38/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0029 - accuracy: 0.1743\n",
      "Epoch 39/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0027 - accuracy: 0.1743\n",
      "Epoch 40/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0026 - accuracy: 0.1743\n",
      "Epoch 41/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0027 - accuracy: 0.1744\n",
      "Epoch 42/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0027 - accuracy: 0.1743\n",
      "Epoch 43/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0026 - accuracy: 0.1743\n",
      "Epoch 44/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0025 - accuracy: 0.1744\n",
      "Epoch 45/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0027 - accuracy: 0.1744\n",
      "Epoch 46/100\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0025 - accuracy: 0.1744\n",
      "Epoch 47/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0024 - accuracy: 0.1744\n",
      "Epoch 48/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0025 - accuracy: 0.1744\n",
      "Epoch 49/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0024 - accuracy: 0.1744\n",
      "Epoch 50/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0022 - accuracy: 0.1744\n",
      "Epoch 51/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0024 - accuracy: 0.1744\n",
      "Epoch 52/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0021 - accuracy: 0.1744\n",
      "Epoch 53/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0023 - accuracy: 0.1744\n",
      "Epoch 54/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0021 - accuracy: 0.1744\n",
      "Epoch 55/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0022 - accuracy: 0.1744\n",
      "Epoch 56/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0023 - accuracy: 0.1744\n",
      "Epoch 57/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0022 - accuracy: 0.1744\n",
      "Epoch 58/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0022 - accuracy: 0.1744\n",
      "Epoch 59/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0021 - accuracy: 0.1744\n",
      "Epoch 60/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0019 - accuracy: 0.1745\n",
      "Epoch 61/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0022 - accuracy: 0.1744\n",
      "Epoch 62/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0019 - accuracy: 0.1745\n",
      "Epoch 63/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0020 - accuracy: 0.1745\n",
      "Epoch 64/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0019 - accuracy: 0.1745\n",
      "Epoch 65/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0022 - accuracy: 0.1744\n",
      "Epoch 66/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0020 - accuracy: 0.1744\n",
      "Epoch 67/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0019 - accuracy: 0.1745\n",
      "Epoch 68/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0018 - accuracy: 0.1745\n",
      "Epoch 69/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0018 - accuracy: 0.1744\n",
      "Epoch 70/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0018 - accuracy: 0.1745\n",
      "Epoch 71/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0018 - accuracy: 0.1745\n",
      "Epoch 72/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0017 - accuracy: 0.1745\n",
      "Epoch 73/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0018 - accuracy: 0.1745\n",
      "Epoch 74/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0019 - accuracy: 0.1745\n",
      "Epoch 75/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0016 - accuracy: 0.1745\n",
      "Epoch 76/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0016 - accuracy: 0.1745\n",
      "Epoch 77/100\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0019 - accuracy: 0.1744\n",
      "Epoch 78/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0016 - accuracy: 0.1745\n",
      "Epoch 79/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0017 - accuracy: 0.1745\n",
      "Epoch 80/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0016 - accuracy: 0.1744\n",
      "Epoch 81/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0016 - accuracy: 0.1745\n",
      "Epoch 82/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0015 - accuracy: 0.1745\n",
      "Epoch 83/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0015 - accuracy: 0.1745\n",
      "Epoch 84/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0016 - accuracy: 0.1745\n",
      "Epoch 85/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0016 - accuracy: 0.1745\n",
      "Epoch 86/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0016 - accuracy: 0.1745\n",
      "Epoch 87/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1745\n",
      "Epoch 88/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1745\n",
      "Epoch 89/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1745\n",
      "Epoch 90/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0015 - accuracy: 0.1745\n",
      "Epoch 91/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0015 - accuracy: 0.1745\n",
      "Epoch 92/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1745\n",
      "Epoch 93/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0015 - accuracy: 0.1745\n",
      "Epoch 94/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1745\n",
      "Epoch 95/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1745\n",
      "Epoch 96/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1745\n",
      "Epoch 97/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1745\n",
      "Epoch 98/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1745\n",
      "Epoch 99/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1745\n",
      "Epoch 100/100\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4889d43460>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff1da87",
   "metadata": {},
   "source": [
    "### 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89841ab",
   "metadata": {},
   "source": [
    "예측(inference) 단계 과정\n",
    "\n",
    "1. 새로운 입력 문장에 대해서는 훈련 때와 동일한 전처리를 거친다.\n",
    "2. 입력 문장을 토크나이징하고, START_TOKEN과 END_TOKEN을 추가한다.\n",
    "3. 패딩 마스킹과 룩 어헤드 마스킹을 계산한다.\n",
    "4. 디코더는 입력 시퀀스로부터 다음 단어를 예측한다.\n",
    "5. 디코더는 예측된 다음 단어를 기존의 입력 시퀀스에 추가하여 새로운 입력으로 사용한다.\n",
    "6. END_TOKEN이 예측되거나 문장의 최대 길이에 도달하면 디코더는 동작을 멈춘다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cefb64c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8140fa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ae9fe030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 요즘 경제 상황에 대해 어떻게 생각해?\n",
      "출력 : 직접 물어보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'직접 물어보세요 .'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('요즘 경제 상황에 대해 어떻게 생각해?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "beca57a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 어떤 영화 장르를 좋아하니?\n",
      "출력 : 사랑은 복합적인 감정이니까요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'사랑은 복합적인 감정이니까요 .'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"어떤 영화 장르를 좋아하니?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78be63c",
   "metadata": {},
   "source": [
    "### <회고>\n",
    "\n",
    "[ 내용 정리 ]\n",
    "\n",
    "Transformer에 대해 알아보는 시간.\n",
    "1. 포지셔널 인코딩(Positional Encoding)\n",
    "- 단어를 임베딩 벡터로 변환 할 때 + 포지셔널 인코딩 사용\n",
    "- RNN(문장에 있는 단어들 순차적으로 받음)과의 차이에서 비롯: Transformer는 문장에 있는 모든 단어를 한꺼번에 입력받음\n",
    "2. 어텐션(Attention)\n",
    "- 주어진 Query에 대해서 모든 Key와의 유사도를 구하고 > Value에 반영\n",
    "- 1) Encoder Self-Attention: 인코더\n",
    "- 2) Masked Decoder Self-Attention: 디코더\n",
    "- 3) Encoder-Decoder Attention: 디코더\n",
    "- 셀프 어텐션: 현재 문장 내 단어들이 서로 유사도를 구하는 경우<br>\n",
    "\n",
    "2-1. 스케일드 닷 프로덕트 어텐션(Scaled Dot Product Attention)\n",
    "- 내적을 통해 단어 벡터 간 유사도를 구하고 + 특정 값을 분모로 나눠주는 방식\n",
    "- $$ Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V $$\n",
    "\n",
    "2-2. 멀티 헤드 어텐션(Multi-Head Attention)\n",
    "- num_heads 변수: 병렬적으로 몇 개의 어텐션 연산을 수행할지를 결정하는 하이퍼파라미터\n",
    "- 문장의 길이: 행, d_model: 열\n",
    "- 병렬로 수행하면: 서로 다른 셀프 어텐션 결과를 얻을 수 있다\n",
    "\n",
    "3. 마스킹(Masking)\n",
    "- 1) 패딩 마스킹(Padding Masking) : 패딩\n",
    "- 2) 룩 어헤드 마스킹(Look-ahead Masking) : 다음 단어 가리기\n",
    "<br>(transformer의 특성 때문, 한꺼번에 문장을 입력받아서, 차례차례 진행하려고)\n",
    "4. 인코더(Encoder)\n",
    "- 하나의 인코더 층은 두 개의 서브 층으로 이루어진다\n",
    "- 1) 셀프 어텐션(Self attention)\n",
    "- 2) 피드 포워드 신경망(Feed Forward Neural Network)\n",
    "- 이렇게 구현한 인코더 층을 임베딩 층과 포지셔널 인코딩을 연결하고, 원하는 만큼 인코더 층을 쌓음\n",
    "5. 디코더(Decoder)\n",
    "- 디코더 층은 세 개의 서브 층으로 이루어진다\n",
    "- 1) 셀프 어텐션(Self Attention)\n",
    "- 2) 인코더-디코더 어텐션(Encoder-Decoder Attention): Query가 디코더의 벡터인 반면에 Key와 Value가 인코더의 벡터라는 특징\n",
    "- 3) 피드 포워드 신경망(Feed Forward)\n",
    "- 모든 어텐션: 스케일드 닷 프로덕트 어텐션을 멀티 헤드 어텐션으로 병렬적으로 수행\n",
    "- 이렇게 구현한 디코더 층을 임베딩 층과 포지셔널 인코딩을 연결하고, 원하는 만큼 디코더 층을 쌓음\n",
    "\n",
    "<br>\n",
    "[ 모델 학습 결과 ] <br>\n",
    "\n",
    "1) 10번 돌렸을 때\n",
    "- Q: 하루가 또 가네요 / A: 더 많이 드시면 더 무너져요.\n",
    "- Q: 신나요 / A: 저도 같이 가요.\n",
    "\n",
    "2) 30번 돌렸을 때\n",
    "- Q: 하루가 또 가네요 / A: 다시 아침이 올 거예요 .\n",
    "- Q: 신나요 / A: 저도요 !\n",
    "\n",
    "3) 100번 돌렸을 때(loss: 0.0013, accuracy: 0.1745)\n",
    "- Q: 하루가 또 가네요 / A: 다시 아침이 올 거예요\n",
    "- Q: 신나요 / A: 마음의 준비를 하세요\n",
    "\n",
    "4) 100번 돌렸을 때\n",
    "- Q: 요즘 경제 상황에 대해 어떻게 생각해? / A: 직접 물어보세요\n",
    "- Q: 어떤 영화 장르를 좋아하니? / A: 사랑은 복합적인 감정이니까요.\n",
    "\n",
    "<br> epoch 값을 늘려서 진행할수록 모델 학습 결과가 좋아지는 것을 확인할 수 있었다. <br>\n",
    "하지만 일상적인 대화에는 답변을 비교적 잘하게 되었지만, <br>\n",
    "심화된 질문에는 제대로 된 답을 하지 못하는 것을 발견하였다. <br>\n",
    "모델 학습을 할 때 다양한 질문/답에 대한 데이터를 제공하는 것이 중요할 것 같다. <br>\n",
    "아니면 관련 주제에 대해서만 질문/답을 할 수 있는 것으로 보인다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
