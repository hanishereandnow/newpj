{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7b9e1f5",
   "metadata": {},
   "source": [
    "# 회귀모델 평가 지표, 손실함수 대표 4가지와 가장 많이 쓰는 함수는?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2a875d",
   "metadata": {},
   "source": [
    "## 1. MAE(Mean Absolute Error)\n",
    "![](https://velog.velcdn.com/images%2Fhyesoup%2Fpost%2Fc6e824a8-2228-4eec-b8dd-a91f8140e0ff%2Fimage.png)\n",
    "![](https://velog.velcdn.com/images%2Ftyhlife%2Fpost%2F2b76919d-6ed1-4ad6-a7d1-9054bab0ab65%2Fimage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d349640",
   "metadata": {},
   "source": [
    "- (실제 값 - 예측 값) 차이의 절댓값의 평균\n",
    "- 가장 직관적, 예측 변수와 단위가 같다 <br>\n",
    "(기온을 예측하는 모델의 MAE가 3이라면 이 모델은 평균적으로 3도 정도를 잘못 예측하는 것)\n",
    "- 절댓값을 씌우기 때문에 underestimate / overestimate 파악 어렵다\n",
    "- 스케일에 의존적이다 (MAE, MSE, RMSE 동일)\n",
    "- 0에 가까울수록 좋다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ce0652",
   "metadata": {},
   "source": [
    "## 2. MSE(Mean Squared Error)\n",
    "![](https://velog.velcdn.com/images%2Frcchun%2Fpost%2Fac220735-2d93-46e0-8812-d9772b191c85%2Fimage.png)\n",
    "![](https://velog.velcdn.com/images%2Ftyhlife%2Fpost%2F729979b2-cf14-4b2b-9f68-520ac1d0d9b9%2Fimage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373e90c4",
   "metadata": {},
   "source": [
    "- (실제 값 - 예측 값) 차이의 제곱의 평균\n",
    "- 직관적\n",
    "- 예측 변수와 단위가 다르다 <br>\n",
    "(ex. 기온을 예측하는 모델의 MSE가 4라면 이 모델은 평균적으로 2도 정도 잘못 예측하는 것)\n",
    "- 스케일에 의존적이다\n",
    "- 제곱(=넓이)하기 때문에 이상치(outlier)에 더 민감하다\n",
    "- 제곱(=넓이)하기 때문에 1미만의 에러는 더 작아지고, 그 이상의 에러는 더 커진다\n",
    "- underestimate / overestimate 파악 어렵다\n",
    "- 0에 가까울수록 좋다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412ba494",
   "metadata": {},
   "source": [
    "## 3. RMSE(Root Mean Squared Error)\n",
    "![](https://velog.velcdn.com/images%2Frcchun%2Fpost%2F1b023dc8-c9ef-4be8-bab1-de4a49ff039c%2Fimage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16b3aca",
   "metadata": {},
   "source": [
    "- (실제 값 - 예측 값) 차이의 제곱의 평균에 루트를 씌운 것\n",
    "- 직관적, 예측 변수와 단위가 같다\n",
    "- 제곱된 값을 다시 루트로 풀어주기 때문에 값의 왜곡이 MSE보다 덜 심하다\n",
    "- 스케일에 의존적이다\n",
    "- underestimate / overestimate 파악 어렵다\n",
    "- 0에 가까울수록 좋다\n",
    "- <b> 특히 많이 사용된다 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7837534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(a, b):\n",
    "    mse = ((a - b) ** 2).mean()  # 두 값의 차이의 제곱의 평균\n",
    "    rmse = mse ** 0.5        # MSE의 제곱근\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f48428",
   "metadata": {},
   "source": [
    "## 4. R-squared(Coefficient of determination, 결정계수)\n",
    "![](https://velog.velcdn.com/images%2Fljs7463%2Fpost%2F69764323-988c-4cc8-83fe-4d71b1c596aa%2Fbandicam%202021-06-13%2020-35-43-297.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d913b56f",
   "metadata": {},
   "source": [
    "- 현재 사용하고 있는 x변수가 y변수의 분산을 얼마나 줄였는가\n",
    "- 독립변수가 종속변수를 얼마나 잘 설명하는지\n",
    "- 단순히 y평균값 모델(기준 모델)을 사용했을 때 대비, 우리가 가진 x 변수를 사용함으로써 얻는 성능 향상의 정도\n",
    "- 1에 가까우면 데이터를 잘 설명하는 모델, 0에 가까울 수록 설명을 못하는 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d515e93",
   "metadata": {},
   "source": [
    "# Gradient Descent Method(경사하강법), 어떤 식으로 이해했는지?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fa2949",
   "metadata": {},
   "source": [
    "▶ 손실함수의 loss를 줄일 수 있도록 하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abba331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(x, w, b, y):\n",
    "    predictions = model(x, w, b)\n",
    "    L = RMSE(predictions, y)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f8e9e7",
   "metadata": {},
   "source": [
    "위의 손실함수에서 직접 수정이 가능한 값은 w, b값 <br>\n",
    "\n",
    "우리는 손실함수의 값이 0이 되기를(최소한 0에 가까워지기를) 바란다 <br>\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/E-7-4.max-800x600_aN5VFfU.png)\n",
    "\n",
    "최적의 b값을 알아냈다고 가정했을 때 w값을 알아내기 위해서, <br>\n",
    "기울기(gradient)가 0이 되는 w값을 찾는다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b616f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치미분(근사한 미분계수 값 찾기)으로 활용하기\n",
    "def gradient(x, w, b, y):\n",
    "    dw = (loss(x, w + 0.0001, b, y) - loss(x, w, b, y)) / 0.0001\n",
    "    db = (loss(x, w, b + 0.0001, y) - loss(x, w, b, y)) / 0.0001\n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021fac6e",
   "metadata": {},
   "source": [
    "참고: https://www.datatechnotes.com/2019/02/regression-model-accuracy-mae-mse-rmse.html\n",
    "https://velog.io/@tyhlife/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%ED%9A%8C%EA%B7%80-%EB%AA%A8%EB%8D%B8%EC%9D%98-%ED%8F%89%EA%B0%80-%EC%A7%80%ED%91%9C\n",
    "LMS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
